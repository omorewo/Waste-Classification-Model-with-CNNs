{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch    \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = 'DATASET'\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms =transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "#train_data = datasets.ImageFolder(data_dir + '/TRAIN', transform=train_transforms)\n",
    "#test_data = datasets.ImageFolder(data_dir + '/TEST', transform=test_transforms)\n",
    "\n",
    "classes = ['Organic', 'Inorganic']\n",
    "\n",
    "#now check if they've loaded correctly\n",
    "print(\"Number of train images: \", (len(train_data)))\n",
    "print(\"Number of test images: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# access the last layer in the net\n",
    "n_inputs = vgg16.classifier[6].in_features\n",
    "\n",
    "# create new layer to have original number of in_features and out_features equal to number of classes we have in our data\n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "\n",
    "# overwrite last layer with our layer\n",
    "vgg16.classifier[6] = last_layer\n",
    "\n",
    "# check if it's correct\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    #keep track of training loss\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_i, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()             #clear the gradients\n",
    "        output = vgg16(data)              #do the forward pass\n",
    "        loss = criterion(output, target)  #calculate loss\n",
    "        loss.backward()                   #do the backward pass\n",
    "        optimizer.step()                  #perform parameter update\n",
    "        train_loss += loss.item()         #update training loss\n",
    "        \n",
    "        if batch_i:    # print training loss every specified number of mini-batches\n",
    "            print('Epoch %d, Batch %d loss: %.16f' %\n",
    "                  (epoch, batch_i + 1, train_loss / 20))\n",
    "            train_loss = 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
